\section{Probability}

\begin{frame}{assiomi e implementazioni}
\begin{block}{Osservabile sperimentale come variabile stocastica}
Esperimento: procedura definita
\end{block}

\begin{block}{Spazio dei risultati}

\end{block}



\end{frame}

\begin{wordonframe}{Descrizione}

\end{wordonframe}

\section{Compiti}\linkdest{compiti}

\begin{wordonframe}{Combinazione p-value per 10 osservabili indipendenti (16/07/18)}
	Fit di massima likelihood per le 10 osservabili (binned) basandosi su teoria: istogrammi suff. popolati per GOF test di Pearson con 30 dof (31 bins?)
	\begin{table}[h!]
		\centering
		\begin{tabular}{||cccccc||} 
			$\chi^2(/30?)$&38.33&40.87&30.70&36.91&39.97\\
			&36.97&20.48&32.34&41.32&41.41\\
			$P(\chi^2_{30}<x)$&0.859&0.911&0.570&0.820&0.894\\
			&0.822&0.096&0.648&0.918&0.920\\
		\end{tabular}
	\end{table}
	Impressione che ci siano troppi valori alti del $\chi^2$: come risolvere il dubbio in maniera rigorosa?
	\begin{itemize}
	\item \mykeyword{additivit\'a del $\chi^2$}: somma quadrati di RV normali standard. 
	\begin{columns}[T]\begin{column}{0.5\textwidth}
			Sommando $\chi^2$ in tab si ottiene RV con pdf $\chi^2_{300}$ approssimabile con gaussiana con $\sigma=\sqrt{2N}\approx24.5$.
			$\sum_i\chi^2_i=359.3$, siamo a $1.21\sigma$
		\end{column}\begin{column}{0.5\textwidth}
			%\begin{figure}[!ht]\includegraphics[trim={0cm 0cm 0 0},clip, keepaspectratio,width=\textwidth]{boh}\label{fig:boh}\end{figure}
	\end{column}\end{columns}
	\item KS test: campione di 10 valori in accordo con pdf $\chi^2_{30}$ (cumulante $\prob{(\chi^2_{30}<x)}$ in tabella). Calcolo $F_n(x_{k-1})-F_n(x_k)$ e $F_n(x_k)-F_n(x_k)$:  $|0-0.096|$, $|0.1-0.57|$, $|0.2-0.648|$, $|0.3-0.82|$, $|0.4-0.822|$, $|0.5-0.859|$, $|0.6-0.894|$, $|0.7-0.914|$, $|0.8-0.918|$, $|0.9-0.926|$; $\Delta=0.52$??
	\item Combinazione diretta p-values: $p_i=1-\prob{(\chi^2_{30}<x)}$, \mykeyword{pdf somma log p-values} $-2\log{(\prod^Np_i)}$ ha pdf $\chi^2_{2N}$
	\item Test binned: hist of p-values (3-4) e considero LR con pdf uniforme (\mykeyword{pdf p-value}) e quindi usarlo per test basato su pdf asintotica (esatta, calcolandola)
	\item Considerare max(min) dei p-values e usare pdf $x_M$ per test
	\item Test della mediana
	\item Test basato su propriet\'a pdf $\chi^2_{30}$: test varianza $2N$; test secondo momento attorno a media nominale 30.
\end{itemize}
\end{wordonframe}

\begin{wordonframe}{Stimatori, confidence/credible interval per parametro m di pdf uniforme da misura della mediana(16/07/18)}
\begin{columns}[T]\begin{column}{0.5\textwidth}
x RV $U(0,m)$; $2k+1=3$ misura la mediana $x_2=3.4$
\begin{block}{MLE estimator, bias, incertezza statistica}
\begin{align*}
&\prob{(\mu=x_2)}=6\frac{\mu}{m^2}(1-\frac{\mu}{m})\\
&\hat{\mu}_{MLE}=3/2\mu\\
&\E{[\hat{m}]}=\frac{3}{2}\E{[\mu]}\frac{3}{2}\int_0^{m}\mu\prob{(\mu)}\,d\mu\\
&=\frac{3}{4}m\\
&\hat{m}'=\frac{4}{3}\hat{m}=2\mu\\
&\var{[\hat{m}]}=\sigma^2_{\hat{m}}=\frac{9}{4}\var{\mu}=\frac{9}{4}\sigma_{\mu}^2\\
&\var{[\hat{m}']}=\sigma^2_{\hat{m}'}=4\var{\mu}=4\sigma_{\mu}^2\\
&\sigma^2_{\mu}=\exv{\mu^2}-\exv{\mu}^2=\frac{m^2}{20}
\end{align*}
Le varianze sono funzione del valore di m: le stimo usando $\hat{m}$
\end{block}
\end{column}\begin{column}{0.5\textwidth}
Likelihood pdf uniforme: \begin{equation*}L_x(m)=\left\{\begin{array}{c}
0\ m<x\\
1/m\ m\geq x\\
\end{array}\right.
\end{equation*}
Determinazione $p(\mu=x_2)$ dove $\mu$ pu\'o essere vista come seconda misura pi\'u grande o mediana; per $2k+1$ misure
\begin{align*}
&\prob{(\mu;m)}=\prob{(\mu)}F(\mu)^k[1-F(\mu)]^k\\
&(2k+1)\binom{2k}{k}\\
&\prob{(\mu;m)}=\frac{1}{m}(\frac{\mu}{m})^k(1-\frac{\mu}{m})^k\frac{(2k+1)!}{k!k!1!}
\end{align*}
\vspace{5cm}
\begin{block}{\mykeyword{Stima bayesiana di m}}
Assumo prior uniforme in $\log{m}$: $\prob{(m)}\propto\frac{1}{m}$, \mykeyword{posterior} $\pi(m)\propto L(\mu|m)\prob{(m)}=\frac{6\mu}{m^3}-\frac{6\mu^2}{m^4}$ ($\prob{(H)}=\frac{\prob{(E|H)\prob{(H)}}}{\prob{(E)}}$): la posterior va normalizzata tra $[\mu,+\infty]$ (likelihood nulla  in $[0,\mu]$), $\pi(m)=\frac{3\mu^2}{m^3}-\frac{3\mu^3}{m^4}$, il massimo fornisci una stima bayesiana di m: $\hat{m}=\frac{4}{3}\mu$.
\end{block}
\end{column}\end{columns}
\end{wordonframe}

\begin{wordonframe}{Stimatori, confidence/credible interval per parametro m di pdf uniforme da misura della mediana(16/07/18)}
	\begin{columns}[T]\begin{column}{0.5\textwidth}
			\begin{block}{MLE estimator, bias, incertezza statistica}
				\begin{align*}
				&\var{[\hat{m}']}=\sigma^2_{\hat{m}'}=4\var{\mu}=4\sigma_{\mu}^2\\
				&\sigma^2_{\mu}=\exv{\mu^2}-\exv{\mu}^2=\frac{m^2}{20}
				\end{align*}
				Le varianze sono funzione del valore di m: le stimo usando $\hat{m}$
			\end{block}
		\end{column}\begin{column}{0.5\textwidth}
			\begin{block}{\mykeyword{Stima bayesiana di m}}
				Assumo prior uniforme in $\log{m}$: $\prob{(m)}\propto\frac{1}{m}$, \mykeyword{posterior} $\pi(m)\propto L(\mu|m)\prob{(m)}=\frac{6\mu}{m^3}-\frac{6\mu^2}{m^4}$ ($\prob{(H)}=\frac{\prob{(E|H)\prob{(H)}}}{\prob{(E)}}$): la posterior va normalizzata tra $[\mu,+\infty]$ (likelihood nulla  in $[0,\mu]$), $\pi(m)=\frac{3\mu^2}{m^3}-\frac{3\mu^3}{m^4}$, il massimo fornisci una stima bayesiana di m: $\hat{m}=\frac{4}{3}\mu$.
			\end{block}
	\end{column}\end{columns}
\end{wordonframe}

\begin{wordonframe}{Stimatori, confidence/credible interval per parametro m di pdf uniforme da misura della mediana(16/07/18)}
	\begin{block}{Limite superiore/bilaterale}
		\mykeyword{Limite superiore per m di $U(0,m)$ da mediana campionaria}: $\int_{\mu}^m6\frac{\tilde{\mu}}{m^2}(1-\frac{\tilde{\mu}}{m})\,d\tilde{\mu}=\cl=0.9$, con $y=\frac{\mu}{m}$ si risolve $F(\mu)=y^2(3-2y)=1-\cl$ ha soluzione $y=0.1958$ quindi $m<\frac{\mu}{0.1958}$.
		\mykeyword{Limite bilaterali simmetrici per m da mediana campionaria}: $F(\mu)=y^2(3-2y)=(1-\cl)/2$ $y_+=0.13535$, $\int_{\mu}^m6\frac{\tilde{\mu}}{m^2}(1-\frac{\tilde{\mu}}{m})\,d\tilde{\mu}=(1-\cl)/2$ quindi $F(\mu)=y^2(3-2y)=(1+\cl)/2$ e $y_-=0.8647$: Limiti bilaterali con $\cl=0.9$ sono $\frac{\mu}{0.8647}<m<\frac{\mu}{0.13535}$
	\end{block}
	\begin{block}{Limiti credibilit\'a Bayesiana}
		prior uniform, $\cred=90\%$. La posterior \'e $\pi(m)=\frac{2\mu}{m^2}-\frac{2\mu^2}{m^3}$ diversa da zero in $[\mu,+\infty]$ e la cumulante $F(m)=\int_{\mu}^m\pi(\tilde{m})\,d\tilde{m}=1+\mu(\frac{\mu}{m^2}-\frac{2}{m})$:
		\begin{align*}
		&F(m_{min})=\frac{1-\cl}{2}\\
		&F(m_{max})=\frac{1+\cl}{2}\\
		&\frac{\mu}{1-\sqrt{(1-\cl)/2}}<m<\frac{\mu}{1-\sqrt{(1+\cl)/2}}
		\end{align*}
		dove ho scelto le soluzioni maggiori di $\mu$, per il limite superiore si ha $m<66.26$.
	\end{block}
	\begin{block}{Limiti confidenza al $90\%\cl$ a la FC}
		Imponiamo il LR-ordering e coverage $90\%$
		\begin{equation*}
		\lambda\propto\mu\prob{(\mu;m)}=6\frac{\mu^2}{m^2}(1-\frac{\mu}{m})
		\end{equation*}
		LR \'e unimodale: un intervallo con $\lambda(m_1)=\lambda(m_2)$, mentre il coverage richiede $\int_{m_1}^{m_2}\prob{(\mu;m)}\,d\mu=\cl$ da cui si ottiene il sistema di equazioni
		\begin{align*}
		&y_2^3-y_1^3=\cl\\
		&y_2^2-y_1^2=\cl\\
		&y_1=\frac{m_1}{m},\ y_1=\frac{m_1}{m}\\
		&\frac{\mu}{0.96804}<m<\frac{\mu}{0.192606}
		\end{align*}
	\end{block}
	\begin{block}{$2k+1$ misure: propriet\'a statistica mediana per costruzione estimatori}
		pdf per mediana campionaria
		\begin{equation*}
		\prob{(\mu;m)}=\frac{1}{m}(\frac{\mu}{m})^k(1-\frac{\mu}{m})^k\frac{(2k+1)!}{k!k!1!}
		\end{equation*}
		\mykeyword{stimatore massima likelihood}:
		\begin{align*}
		&\log{L(m)}=\log{\frac{1}{m}}+k\log{\frac{\tilde{m}}{m}}+k\log{(1-\frac{\tilde{m}}{m})}+\const{}\\
		&\TDy{m}{\log{L}}=0 \Rightarrow \hat{m}=\frac{2k+1}{k+1}\tilde{m}
		\end{align*}
		Bias estimatore:
		\begin{align*}
		&\E{[\hat{m}]}=\frac{2k+1}{k+1}\E{[\tilde{m}]}\\
		&\E{[\tilde{m}]}=\int_0^m\tilde{m}\prob{(\tilde{m};m)}\,d\tilde{m}\\
		&=\frac{(2k+1)!}{k!k!1!}m\int_0^1x^{k+1}(1-x)^k\,dx\ (x=\frac{\tilde{m}}{m})\\
		&\E{[\tilde{m}]}=\frac{(2k+1)!}{k!k!1!}m\frac{\Gamma(k+1)\Gamma(k+2)}{\Gamma(2k+3)}=\frac{m}{2}\ (\Gamma(k+1)=k!)\\
		&\E{[\hat{m}]}=\frac{2k+1}{2(k+1)}m\\
		&b=m-\frac{2k+1}{2(k+1)}=\frac{1}{2(k+1)}m\to0
		\end{align*}
		Varianza
		\begin{align*}
		&\E{[\tilde{m}^2]}=\frac{(2k+1)!}{k!k!1!}m^2\int_0^1x^{k+2}(1-x)^k\,dx\\
		&=\frac{(2k+1)!}{k!k!1!}m^2\frac{\Gamma(k+1)\Gamma(k+3)}{\Gamma(2k+4)}\\
		&=\frac{(k+1)(k+1)}{(2k+3)(2k+2)}m^2\\
		&\var{[\tilde{m}]}=\E{[\tilde{m}^2]}-\E{[\tilde{m}]}^2=m^2\frac{1}{4(2k+3)}\\
		&\var{[\hat{m}]}=(\frac{2k+1}{k+1})^2\var{[\tilde{m}]}\to0
		\end{align*}
		\mykeyword{Efficienza estimatore mediana campionaria per pdf uniforme}: non si pu\'o usare MVB come riferimento assoluto dato che per pdf uniforme $I_F$ non \'e proporzionale al numero di misure; efficienza relativa rispetto a stimatore ricavato da statistica suff. $x_M$ $\var{[x_M]}=frac{m^2}{k^2}$: il MLE ricavato da mediana \'e meno efficiente ed efficienza relativa va a 0.
	\end{block}
\end{wordonframe}

\begin{wordonframe}{Stime limite superiore dati da pdf uniforme (Compito 09/11/18)}
\begin{block}{\keyword{pdf di $X_{(2)}$ per N estrazioni da pdf uniforme}}
\begin{align*}
&\prob{X_{(k)}<x}=\sum_{i=k}^nc(n,i)F(x)^i[1-F(x)]^{n-i}\\
&\PDof{p}\sum_{i=k}^nc(n,i)p^{i}[1-p]^{n-i}=nC(n-1,k-1)p\expy{k-1}(1-p)\expy{k-1}\\
&\prob{(X_{(k)})}=nC(n-1,k-1)f(x)F(x)\expy{k-1}(1-F(x))\expy{k-1}\\
&\prob{(x_2;m)}=N(N-1)\frac{1}{m^N}x_2\expy{N-2}(m-x_2)
\end{align*}
\end{block}
\begin{block}{Efficienza stimatore di m da statistica $x_2$}
Massimizzando $L(m)$ per m si ha $\hat{m}=\frac{N}{N-1}x_2$, si corregge per il bias $\E{[\hat{m}]}-m=-\frac{1}{N+1}m$ definendo $\hat{m}'=\frac{N+1}{N}\hat{m}=\frac{N+1}{N-1}x_2$; per calcolare la varianza
\begin{align*}
\var{[\hat{m}']}=\E{\hat{m}'^2}-\E{[\hat{m}']}^2\\
\E{[\hat{m}'^2]}=\frac{(N+1)^2}{(N-1)^2}\E{[x_2^2]}=\frac{2}{(N-1)(N+2)}m^2
\end{align*}
\end{block}
\begin{block}{Efficienza stimatore di m da statistica $x_M$}
\keyword{pdf di $x_M$} \'e $\frac{N}{m}(\frac{x_M}{m})^{N-1}$: stima di \keyword{massima likelihood di m da statistica $x_M$}: $\hat{m}=x_M$; stimatore unbiased $\hat{m}'=\frac{N+1}{N}\hat{m}$.
La varianza di $\hat{m}'$ \'e
\begin{align*}
&\E{[\hat{m}'^2]}-\E{\hat{m'}}^2=\frac{(N+1)^2}{N^2}\frac{N}{N+2}m^2-m^2=\frac{1}{N(N+2)}m^2
\end{align*}
\end{block}
\begin{block}{Confronto efficienza stimatore da $x_2$ vs $x_M$}
L'\keyword{efficienza relativa di due stimatori} si ottiene:
\begin{equation*}
\epsilon_r=\frac{\var{[\hat{m'}_{M}]}}{\var{[\hat{m'}_{x_2}]}}
\end{equation*}
\end{block}
\begin{block}{\keyword{Combinazione likelihood 2 misure di $x_2$}}
Calcolare MLE massimizzando likelihood combinata:
\begin{align*}
&L(m_1,m_2;x_2'x_2'')=N^2(N-1)^2\frac{1}{m^{2N}}x_2'\expy{N-1}x_2''\expy{N-2}(m-x_2')(m-x_2'')\\
&2(N-1)m^2+(x_2'+x_2'')(2N-1)m-2N(x_2'x_2'')=0\\
&\hat{m}_{\pm}=\frac{(x_2'+x_2'')(2N-1)\pm\sqrt{(x_2'+x_2'')^2(2N-1)^2-16N(N-1)x_2'x_2''}}{4(N-1)}
\end{align*}
quale soluzione \'e nella regione in cui la likelihood \'e diversa da zero? Asintoticamente $\hat{m}=\max{(x_2',x_2'')}$
\end{block}
\begin{block}{\keyword{Test bilaterale di ipotesi composte: dati da pdf uniforme con $m_1\neq m_2$?}}

\end{block}
\end{wordonframe}

\begin{wordonframe}{math basic}
\begin{block}{Soluzione equazione di secondo grado}
\begin{align*}
&4a(ax^2+bx+c)=0\\
&4a^2x^2+4abx+4ac+b^2-b^2=0\\
&(2ax+b)^2=b^2-4ac
\end{align*}
\end{block}

\end{wordonframe}
